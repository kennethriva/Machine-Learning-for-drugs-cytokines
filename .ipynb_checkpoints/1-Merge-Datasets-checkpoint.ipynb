{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets\n",
    "\n",
    "Create a dataset from different sources: initial dataset, protein and drug descriptors, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ds_utils # our set of useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an working folder with the initial files and the new datasets and the name of the file for the final dataframe.\n",
    "\n",
    "Define the files that you want to merge into a final dataset as a dataframe:\n",
    "- create a list with the files to merge (the order in the list is the merge order)\n",
    "- create a list with fields to use for the merge (each field i corresponds to i, i+1 files)\n",
    "- create a list with the fieds to remove from the final merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkingFolder     = './datasets/'\n",
    "FinalDataSetFile  = 'ds_raw.csv'\n",
    "\n",
    "Files2Merge  = ['Chembl_Cytokines.csv','Drug_descriptors.csv',\n",
    "               'Protein_descriptors.csv','Protein_descriptors2.csv']\n",
    "\n",
    "# list of lists = you can merge 2 datasets using more fields! (= number of merge operations)\n",
    "Fields2Merge= [['CANONICAL_SMILES'], ['PROTEIN_ACCESSION'], ['PROTEIN_ACCESSION']]\n",
    "\n",
    "# Fields to remove from the final merged dataframe\n",
    "Fields2Remove = ['No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of file data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Checking: Chembl_Cytokines.csv\n",
      "\n",
      "Data points = 14573\n",
      "\n",
      "Columns (output + features)= 18\n",
      "\n",
      "Data types = [dtype('O') dtype('int64') dtype('float64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['CMPD_CHEMBLID', 'CANONICAL_SMILES', 'PROTEIN_ACCESSION', 'ACTIVITY_ID',\n",
      "       'STANDARD_TYPE_UNITSj', 'STANDARD_VALUE', 'ASSAY_CHEMBLID',\n",
      "       'ASSAY_TYPE', 'ASSAY_ORGANISM', 'CURATED_BY', 'TARGET_CHEMBLID',\n",
      "       'TARGET_TYPE', 'ORGANISM', 'TARGET_MAPPING', 'AVGJs', 'SDJs', 'z-score',\n",
      "       'Lij'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical features: ['CMPD_CHEMBLID', 'CANONICAL_SMILES', 'PROTEIN_ACCESSION', 'STANDARD_TYPE_UNITSj', 'ASSAY_CHEMBLID', 'ASSAY_TYPE', 'ASSAY_ORGANISM', 'CURATED_BY', 'TARGET_CHEMBLID', 'TARGET_TYPE', 'ORGANISM', 'TARGET_MAPPING']\n",
      "\n",
      "Columns with NaN:  0  /  18\n",
      "\n",
      "No of data points with NaN: 0  /  14573\n",
      "\n",
      "-> Checking: Drug_descriptors.csv\n",
      "\n",
      "Data points = 7178\n",
      "\n",
      "Columns (output + features)= 145\n",
      "\n",
      "Data types = [dtype('int64') dtype('O') dtype('float64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['No', 'CANONICAL_SMILES', 'ALogP', 'ALogp2', 'AMR', 'apol',\n",
      "       'naAromAtom', 'nAromBond', 'nAtom', 'ATSc1',\n",
      "       ...\n",
      "       'topoShape', 'nRotB', 'LipinskiFailures', 'TopoPSA', 'VAdjMat', 'MW',\n",
      "       'WPATH', 'WPOL', 'XLogP', 'Zagreb'],\n",
      "      dtype='object', length=145)\n",
      "\n",
      "Categorical features: ['CANONICAL_SMILES']\n",
      "\n",
      "Columns with NaN:  0  /  145\n",
      "\n",
      "No of data points with NaN: 0  /  7178\n",
      "\n",
      "-> Checking: Protein_descriptors.csv\n",
      "\n",
      "Data points = 13\n",
      "\n",
      "Columns (output + features)= 91\n",
      "\n",
      "Data types = [dtype('O') dtype('float64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['PROTEIN_ACCESSION', 'CHOC760101.lag1', 'CHOC760101.lag2',\n",
      "       'CHOC760101.lag3', 'CHOC760101.lag4', 'CHOC760101.lag5',\n",
      "       'CHOC760101.lag6', 'CHOC760101.lag7', 'CHOC760101.lag8',\n",
      "       'CHOC760101.lag9', 'CHOC760101.lag10', 'CHOC760101.lag11',\n",
      "       'CHOC760101.lag12', 'CHOC760101.lag13', 'CHOC760101.lag14',\n",
      "       'CHOC760101.lag15', 'CHOC760101.lag16', 'CHOC760101.lag17',\n",
      "       'CHOC760101.lag18', 'CHOC760101.lag19', 'CHOC760101.lag20',\n",
      "       'CHOC760101.lag21', 'CHOC760101.lag22', 'CHOC760101.lag23',\n",
      "       'CHOC760101.lag24', 'CHOC760101.lag25', 'CHOC760101.lag26',\n",
      "       'CHOC760101.lag27', 'CHOC760101.lag28', 'CHOC760101.lag29',\n",
      "       'CHOC760101.lag30', 'BIGC670101.lag1', 'BIGC670101.lag2',\n",
      "       'BIGC670101.lag3', 'BIGC670101.lag4', 'BIGC670101.lag5',\n",
      "       'BIGC670101.lag6', 'BIGC670101.lag7', 'BIGC670101.lag8',\n",
      "       'BIGC670101.lag9', 'BIGC670101.lag10', 'BIGC670101.lag11',\n",
      "       'BIGC670101.lag12', 'BIGC670101.lag13', 'BIGC670101.lag14',\n",
      "       'BIGC670101.lag15', 'BIGC670101.lag16', 'BIGC670101.lag17',\n",
      "       'BIGC670101.lag18', 'BIGC670101.lag19', 'BIGC670101.lag20',\n",
      "       'BIGC670101.lag21', 'BIGC670101.lag22', 'BIGC670101.lag23',\n",
      "       'BIGC670101.lag24', 'BIGC670101.lag25', 'BIGC670101.lag26',\n",
      "       'BIGC670101.lag27', 'BIGC670101.lag28', 'BIGC670101.lag29',\n",
      "       'BIGC670101.lag30', 'CHAM810101.lag1', 'CHAM810101.lag2',\n",
      "       'CHAM810101.lag3', 'CHAM810101.lag4', 'CHAM810101.lag5',\n",
      "       'CHAM810101.lag6', 'CHAM810101.lag7', 'CHAM810101.lag8',\n",
      "       'CHAM810101.lag9', 'CHAM810101.lag10', 'CHAM810101.lag11',\n",
      "       'CHAM810101.lag12', 'CHAM810101.lag13', 'CHAM810101.lag14',\n",
      "       'CHAM810101.lag15', 'CHAM810101.lag16', 'CHAM810101.lag17',\n",
      "       'CHAM810101.lag18', 'CHAM810101.lag19', 'CHAM810101.lag20',\n",
      "       'CHAM810101.lag21', 'CHAM810101.lag22', 'CHAM810101.lag23',\n",
      "       'CHAM810101.lag24', 'CHAM810101.lag25', 'CHAM810101.lag26',\n",
      "       'CHAM810101.lag27', 'CHAM810101.lag28', 'CHAM810101.lag29',\n",
      "       'CHAM810101.lag30'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical features: ['PROTEIN_ACCESSION']\n",
      "\n",
      "Columns with NaN:  0  /  91\n",
      "\n",
      "No of data points with NaN: 0  /  13\n",
      "\n",
      "-> Checking: Protein_descriptors2.csv\n",
      "\n",
      "Data points = 13\n",
      "\n",
      "Columns (output + features)= 21\n",
      "\n",
      "Data types = [dtype('O') dtype('float64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['PROTEIN_ACCESSION', 'comp_A', 'comp_R', 'comp_N', 'comp_D', 'comp_C',\n",
      "       'comp_E', 'comp_Q', 'comp_G', 'comp_H', 'comp_I', 'comp_L', 'comp_K',\n",
      "       'comp_M', 'comp_F', 'comp_P', 'comp_S', 'comp_T', 'comp_W', 'comp_Y',\n",
      "       'comp_V'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical features: ['PROTEIN_ACCESSION']\n",
      "\n",
      "Columns with NaN:  0  /  21\n",
      "\n",
      "No of data points with NaN: 0  /  13\n"
     ]
    }
   ],
   "source": [
    "# for each file\n",
    "for aFile in Files2Merge:\n",
    "    # df  = os.path.join(WorkingFolder, aFile)\n",
    "    print('\\n-> Checking:', aFile)\n",
    "    \n",
    "    # read the CSV file as dataframe\n",
    "    df = pd.read_csv(os.path.join(WorkingFolder, aFile))\n",
    "    \n",
    "    # data checkings\n",
    "    ds_utils.DataCheckings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all files using fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Merging: ./datasets/Drug_descriptors.csv\n",
      "--> Fields to merge: ['CANONICAL_SMILES']\n",
      "\n",
      "-> Merging: ./datasets/Protein_descriptors.csv\n",
      "--> Fields to merge: ['PROTEIN_ACCESSION']\n",
      "\n",
      "-> Merging: ./datasets/Protein_descriptors2.csv\n",
      "--> Fields to merge: ['PROTEIN_ACCESSION']\n",
      "\n",
      "===> Merged dataset columns\n",
      " Index(['CMPD_CHEMBLID', 'CANONICAL_SMILES', 'PROTEIN_ACCESSION', 'ACTIVITY_ID',\n",
      "       'STANDARD_TYPE_UNITSj', 'STANDARD_VALUE', 'ASSAY_CHEMBLID',\n",
      "       'ASSAY_TYPE', 'ASSAY_ORGANISM', 'CURATED_BY',\n",
      "       ...\n",
      "       'comp_L', 'comp_K', 'comp_M', 'comp_F', 'comp_P', 'comp_S', 'comp_T',\n",
      "       'comp_W', 'comp_Y', 'comp_V'],\n",
      "      dtype='object', length=272)\n"
     ]
    }
   ],
   "source": [
    "# set initial df as the first file data in the list\n",
    "df = pd.read_csv(os.path.join(WorkingFolder, Files2Merge[0]))\n",
    "\n",
    "# merge all the other files to the initial one\n",
    "for i in range(1, len(Fields2Merge) + 1):\n",
    "    aFile = os.path.join(WorkingFolder, Files2Merge[i])\n",
    "    print('\\n-> Merging:', aFile)\n",
    "    \n",
    "    # read the CSV file as dataframe\n",
    "    df2merge = pd.read_csv(aFile)\n",
    "    \n",
    "    # Merge\n",
    "    print('--> Fields to merge:', Fields2Merge[i-1])\n",
    "    df = pd.merge(df, df2merge, on=Fields2Merge[i-1])\n",
    "\n",
    "print('\\n===> Merged dataset columns\\n', df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you need, remove any column from the merged dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(Fields2Remove,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final dataset to disk as CSV file without index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Saving final merged dataset: ds_raw.csv\n",
      "\n",
      "Done! Have fun with your dataset!\n"
     ]
    }
   ],
   "source": [
    "print('\\n-> Saving final merged dataset:', FinalDataSetFile)\n",
    "df.to_csv(os.path.join(WorkingFolder, FinalDataSetFile), index=False)\n",
    "print('\\nDone! Have fun with your dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
