{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Baseline Generator\n",
    "\n",
    "This is the first script to use a set of ML method with default parameters in order to obtain baseline results. We will use the following *sklearn* classifiers:\n",
    "\n",
    "1. KNeighborsClassifier - Nearest Neighbors\n",
    "2. GaussianNB - Gaussian Naive Bayes\n",
    "3. LinearSVC - Linear Support vector machine (SVM)\n",
    "4. SVC - Support vector machine (SVM) with Radial Basis Functions (RBF)\n",
    "5. LogisticRegression - Logistic regression\n",
    "6. MLPClassifier - Multi-Layer Perceptron (MLP) / Neural Networks\n",
    "7. AdaBoostClassifier - AdaBoost\n",
    "8. DecisionTreeClassifier - Decision Trees\n",
    "9. RandomForestClassifier - Random Forest\n",
    "10. GradientBoostingClassifier - Gradient Boosting\n",
    "11. BaggingClassifier - ensemble meta-estimator Bagging\n",
    "12. XGBClassifier - XGBoost\n",
    "\n",
    "*Note: More advanced hyperparameter search will be done in future scripts!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scripts\n",
    "from ds_utils import *\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will show the chosen procedure for the Machine Learning baseline generator.\n",
    "The first step is to create a list of train and test datasets which will be used to generate and estimae a set of performances of more common used algorithms. In order to have a wide approximation several metrics will be used for every model.\n",
    "\n",
    "### Step 1 - List of datasets and classifiers\n",
    "So as a first step lets define a list o datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Files to use for ML baseline generator:\n",
      "Training sets:\n",
      " ['s.ds_MA_tr.csv', 'fs-rf.s.ds_MA_tr.csv', 'pca0.99.s.ds_MA_tr.csv']\n",
      "Test sets:\n",
      " ['s.ds_MA_ts.csv', 'fs-rf.s.ds_MA_ts.csv', 'pca0.99.s.ds_MA_ts.csv']\n"
     ]
    }
   ],
   "source": [
    "# dataset folder\n",
    "WorkingFolder  = './datasets/'\n",
    "# BasicMLResults = 'ML_basic.csv' # a file with all the statistis for ML models\n",
    "\n",
    "# Split details\n",
    "seed = 44          # for reproductibility\n",
    "\n",
    "# output variable\n",
    "outVar = 'Lij'    \n",
    "\n",
    "# parameter for ballanced (equal number of examples in all classes) and non-ballanced dataset \n",
    "class_weight = \"balanced\" # use None for ballanced datasets!\n",
    "\n",
    "\n",
    "# set list of train and test files\n",
    "\n",
    "listFiles_tr = ['s.ds_MA_tr.csv','fs-rf.s.ds_MA_tr.csv','pca0.99.s.ds_MA_tr.csv']\n",
    "listFiles_ts = ['s.ds_MA_ts.csv','fs-rf.s.ds_MA_ts.csv','pca0.99.s.ds_MA_ts.csv']\n",
    "\n",
    "#listFiles_tr = [col for col in os.listdir(WorkingFolder) if ('tr' in col)\n",
    "#                and (col[:5] != 'o.ds_') ]\n",
    "\n",
    "#listFiles_ts = [col for col in os.listdir(WorkingFolder) if ('ts' in col)\n",
    "#                and (col[:5] != 'o.ds_') ]\n",
    "\n",
    "# Check the list of files to process\n",
    "print('* Files to use for ML baseline generator:')\n",
    "print('Training sets:\\n', listFiles_tr)\n",
    "print('Test sets:\\n',listFiles_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once defined our list of datasets, let's call baseline_generator function which will generate a dataframe with all performances for every combination of dataset and algorithm. Remenber we are using a set of algorithms as a baseline where are included basic, complex and ensemble methods. For more information you can call baseline_classifiers method fror the ds_utils.py script to see which algorithms and parameters are being used for the baseline. Another aspect to point out is that weights for algorithms that used this parameter are calculated using set_weights method based on the class_weight.compute_class_weight sklearn method. More information can be found at: https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html.\n",
    "\n",
    "Let's verify the ballance of the classes and create the classifier definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights {0: 0.6773268019594122, 1: 1.90982636148382}\n",
      "**************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " LinearSVC(C=1.0, class_weight={0: 0.6773268019594122, 1: 1.90982636148382},\n",
       "      dual=True, fit_intercept=True, intercept_scaling=1,\n",
       "      loss='squared_hinge', max_iter=20000, multi_class='ovr', penalty='l2',\n",
       "      random_state=0, tol=0.0001, verbose=0),\n",
       " LogisticRegression(C=1.0,\n",
       "           class_weight={0: 0.6773268019594122, 1: 1.90982636148382},\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "           max_iter=10000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False),\n",
       " SVC(C=1.0, cache_size=200,\n",
       "   class_weight={0: 0.6773268019594122, 1: 1.90982636148382}, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "   max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "   verbose=False),\n",
       " AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=50, random_state=0),\n",
       " GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "        n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=0, shuffle=False, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " DecisionTreeClassifier(class_weight={0: 0.6773268019594122, 1: 1.90982636148382},\n",
       "             criterion='gini', max_depth=None, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=0, splitter='best'),\n",
       " RandomForestClassifier(bootstrap=True,\n",
       "             class_weight={0: 0.6773268019594122, 1: 1.90982636148382},\n",
       "             criterion='gini', max_depth=None, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_jobs=-1, oob_score=False, random_state=0,\n",
       "             verbose=0, warm_start=False),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               n_iter_no_change=None, presort='auto', random_state=0,\n",
       "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "          bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "          n_estimators=10, n_jobs=None, oob_score=False, random_state=0,\n",
       "          verbose=0, warm_start=False),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.6, gamma=0.1, learning_rate=0.1,\n",
       "        max_delta_step=0, max_depth=6, min_child_weight=1, missing=None,\n",
       "        n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "        objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "        reg_lambda=1, scale_pos_weight=0.3546536039188244, seed=0,\n",
       "        silent=True, subsample=0.6)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling baseline_classifiers to see which algorithms and parameters are being used. Remember that\n",
    "# baseline_classifiers() need a y_tr_data argument to be executed, it can be any y_tr_data if you just want\n",
    "# to see the output\n",
    "\n",
    "y_tr_data = datasets_parser(listFiles_tr[0], listFiles_ts[0],outVar=outVar, WorkingFolder=WorkingFolder)[1]\n",
    "ML_methods_used = baseline_classifiers(y_tr_data)\n",
    "ML_methods_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Baseline generator for all datasets and ML methods\n",
    "Once settle this. The next step is to call the baseline_generator method which takes as arguments a list of train and test sets we define previously. This function will calculate some metrics for each combination of train-test sets and will create a dataframe with all the performances. The final dataframe is sorted by AUC value, so the first row will correspond to the algorithm and dataset which achieve better perforamce. \n",
    "\n",
    "For each dataset and method we will print here only the test **AUC** and **Accuracy**. The rest of statistics will be save on a local CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Generating Basic Machine Learning baseline...\n",
      "\n",
      "-> Dataset: ./datasets/ s.ds_MA_tr.csv ...\n",
      "class weights {0: 0.6773268019594122, 1: 1.90982636148382}\n",
      "**************************************\n",
      "* Classifier: KNeighborsClassifier ...\n",
      "[0.7180150437949314, 0.7973]\n",
      "* Classifier: LinearSVC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8623860412661033, 0.8324]\n",
      "* Classifier: LogisticRegression ...\n",
      "[0.8614885308452447, 0.8333]\n",
      "* Classifier: SVC ...\n",
      "[0.8535863155122988, 0.8289]\n",
      "* Classifier: AdaBoostClassifier ...\n",
      "[0.7948077047282628, 0.8262]\n",
      "* Classifier: GaussianNB ...\n",
      "[0.6725274370401285, 0.6439]\n",
      "* Classifier: MLPClassifier ...\n",
      "[0.7573957044699149, 0.8076]\n",
      "* Classifier: DecisionTreeClassifier ...\n",
      "[0.7036851832530965, 0.7722]\n",
      "* Classifier: RandomForestClassifier ...\n",
      "[0.7556965704320867, 0.8079]\n",
      "* Classifier: GradientBoostingClassifier ...\n",
      "[0.8066221513421669, 0.8351]\n",
      "* Classifier: BaggingClassifier ...\n",
      "[0.7340890008396306, 0.798]\n",
      "* Classifier: XGBClassifier ...\n",
      "[0.7332476313972148, 0.8029]\n",
      "\n",
      "-> Dataset: ./datasets/ fs-rf.s.ds_MA_tr.csv ...\n",
      "class weights {0: 0.6773268019594122, 1: 1.90982636148382}\n",
      "**************************************\n",
      "* Classifier: KNeighborsClassifier ...\n",
      "[0.7146945284903045, 0.793]\n",
      "* Classifier: LinearSVC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8448444696168006, 0.8234]\n",
      "* Classifier: LogisticRegression ...\n",
      "[0.8353372681700526, 0.824]\n",
      "* Classifier: SVC ...\n",
      "[0.8381058133237943, 0.8224]\n",
      "* Classifier: AdaBoostClassifier ...\n",
      "[0.79883395684597, 0.8327]\n",
      "* Classifier: GaussianNB ...\n",
      "[0.6831047948370172, 0.7075]\n",
      "* Classifier: MLPClassifier ...\n",
      "[0.7616318642282603, 0.8144]\n",
      "* Classifier: DecisionTreeClassifier ...\n",
      "[0.7105940013612946, 0.7791]\n",
      "* Classifier: RandomForestClassifier ...\n",
      "[0.7604121642098778, 0.8069]\n",
      "* Classifier: GradientBoostingClassifier ...\n",
      "[0.8168532236348551, 0.8401]\n",
      "* Classifier: BaggingClassifier ...\n",
      "[0.7455596460634244, 0.8076]\n",
      "* Classifier: XGBClassifier ...\n",
      "[0.7204959285370057, 0.8004]\n",
      "\n",
      "-> Dataset: ./datasets/ pca0.99.s.ds_MA_tr.csv ...\n",
      "class weights {0: 0.6773268019594122, 1: 1.90982636148382}\n",
      "**************************************\n",
      "* Classifier: KNeighborsClassifier ...\n",
      "[0.7153622583578018, 0.7945]\n",
      "* Classifier: LinearSVC ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8283325632579653, 0.8187]\n",
      "* Classifier: LogisticRegression ...\n",
      "[0.8271309972724427, 0.8147]\n",
      "* Classifier: SVC ...\n",
      "[0.8164982437313381, 0.8125]\n",
      "* Classifier: AdaBoostClassifier ...\n",
      "[0.7252477903805166, 0.8063]\n",
      "* Classifier: GaussianNB ...\n",
      "[0.6241689396310595, 0.7208]\n",
      "* Classifier: MLPClassifier ...\n",
      "[0.7526637155391273, 0.7989]\n",
      "* Classifier: DecisionTreeClassifier ...\n",
      "[0.6800001490468455, 0.7502]\n",
      "* Classifier: RandomForestClassifier ...\n",
      "[0.6857747206613706, 0.7852]\n",
      "* Classifier: GradientBoostingClassifier ...\n",
      "[0.7506734433299054, 0.8162]\n",
      "* Classifier: BaggingClassifier ...\n",
      "[0.709197184008267, 0.7905]\n",
      "* Classifier: XGBClassifier ...\n",
      "[0.6971132110155556, 0.7896]\n",
      "---> Saving results ...\n",
      "! Please find your ML results in: ML_baseline_generator.csv\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA_dataset</th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Train Accuracy</th>\n",
       "      <th>MLA Test Accuracy</th>\n",
       "      <th>MLA Test Precission</th>\n",
       "      <th>MLA Test Recall</th>\n",
       "      <th>MLA Test F1_score</th>\n",
       "      <th>MLA Test AUC</th>\n",
       "      <th>MLA Test Matthews Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>[0.96797153 0.62063492]</td>\n",
       "      <td>[0.7993283  0.92544379]</td>\n",
       "      <td>0.742993</td>\n",
       "      <td>0.862386</td>\n",
       "      <td>0.653150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>[0.9661274  0.62289832]</td>\n",
       "      <td>[0.802267   0.92071006]</td>\n",
       "      <td>0.743075</td>\n",
       "      <td>0.861489</td>\n",
       "      <td>0.652573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>[0.95979899 0.61843169]</td>\n",
       "      <td>[0.80184719 0.90532544]</td>\n",
       "      <td>0.734870</td>\n",
       "      <td>0.853586</td>\n",
       "      <td>0.639460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>[0.95345345 0.61187958]</td>\n",
       "      <td>[0.79974811 0.88994083]</td>\n",
       "      <td>0.725169</td>\n",
       "      <td>0.844844</td>\n",
       "      <td>0.624423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>[0.94622595 0.61333333]</td>\n",
       "      <td>[0.80520571 0.87100592]</td>\n",
       "      <td>0.719804</td>\n",
       "      <td>0.838106</td>\n",
       "      <td>0.615126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8215</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>[0.9420078  0.61787234]</td>\n",
       "      <td>[0.81150294 0.8591716 ]</td>\n",
       "      <td>0.718812</td>\n",
       "      <td>0.835337</td>\n",
       "      <td>0.612778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>[0.93765222 0.61073254]</td>\n",
       "      <td>[0.80814442 0.84852071]</td>\n",
       "      <td>0.710253</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.600088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>[0.93897638 0.60334728]</td>\n",
       "      <td>[0.80100756 0.85325444]</td>\n",
       "      <td>0.706863</td>\n",
       "      <td>0.827131</td>\n",
       "      <td>0.595669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>[0.91319752 0.66976264]</td>\n",
       "      <td>[0.86565911 0.76804734]</td>\n",
       "      <td>0.715546</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.607804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>[0.92860589 0.60398614]</td>\n",
       "      <td>[0.80814442 0.82485207]</td>\n",
       "      <td>0.697349</td>\n",
       "      <td>0.816498</td>\n",
       "      <td>0.580628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>[0.90605795 0.66491043]</td>\n",
       "      <td>[0.86649874 0.74674556]</td>\n",
       "      <td>0.703456</td>\n",
       "      <td>0.806622</td>\n",
       "      <td>0.591729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>[0.90008688 0.66486486]</td>\n",
       "      <td>[0.86985726 0.72781065]</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.798834</td>\n",
       "      <td>0.581080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>[0.89951733 0.64978903]</td>\n",
       "      <td>[0.86062133 0.72899408]</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>0.569104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>[0.87568479 0.6440281 ]</td>\n",
       "      <td>[0.87237615 0.65088757]</td>\n",
       "      <td>0.647440</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.521485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>[0.87762988 0.62360802]</td>\n",
       "      <td>[0.85810243 0.66272189]</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>0.760412</td>\n",
       "      <td>0.510937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>[0.87484036 0.62756264]</td>\n",
       "      <td>[0.8627204  0.65207101]</td>\n",
       "      <td>0.639582</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.508559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>[0.87330508 0.62975779]</td>\n",
       "      <td>[0.86523929 0.64615385]</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.755697</td>\n",
       "      <td>0.507211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>[0.87429806 0.60745614]</td>\n",
       "      <td>[0.84970613 0.6556213 ]</td>\n",
       "      <td>0.630620</td>\n",
       "      <td>0.752664</td>\n",
       "      <td>0.493400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>[0.86614818 0.66071429]</td>\n",
       "      <td>[0.88832914 0.61301775]</td>\n",
       "      <td>0.635973</td>\n",
       "      <td>0.750673</td>\n",
       "      <td>0.513946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>[0.86520116 0.6372549 ]</td>\n",
       "      <td>[0.87573468 0.61538462]</td>\n",
       "      <td>0.626129</td>\n",
       "      <td>0.745560</td>\n",
       "      <td>0.496755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>[0.85951787 0.61753959]</td>\n",
       "      <td>[0.868178 0.6     ]</td>\n",
       "      <td>0.608643</td>\n",
       "      <td>0.734089</td>\n",
       "      <td>0.472597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>[0.85720131 0.63346105]</td>\n",
       "      <td>[0.87951301 0.58698225]</td>\n",
       "      <td>0.609337</td>\n",
       "      <td>0.733248</td>\n",
       "      <td>0.478426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>[0.8501395  0.65320334]</td>\n",
       "      <td>[0.89546599 0.55502959]</td>\n",
       "      <td>0.600128</td>\n",
       "      <td>0.725248</td>\n",
       "      <td>0.476187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>[0.84843625 0.63710778]</td>\n",
       "      <td>[0.88832914 0.55266272]</td>\n",
       "      <td>0.591888</td>\n",
       "      <td>0.720496</td>\n",
       "      <td>0.462732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>[0.84754626 0.62887989]</td>\n",
       "      <td>[0.8845508  0.55147929]</td>\n",
       "      <td>0.587642</td>\n",
       "      <td>0.718015</td>\n",
       "      <td>0.455781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>[0.84643289 0.62198391]</td>\n",
       "      <td>[0.88161209 0.54911243]</td>\n",
       "      <td>0.583281</td>\n",
       "      <td>0.715362</td>\n",
       "      <td>0.449175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>[0.84640259 0.61752988]</td>\n",
       "      <td>[0.8790932  0.55029586]</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>0.714695</td>\n",
       "      <td>0.446327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>[0.84756352 0.57990315]</td>\n",
       "      <td>[0.8543241  0.56686391]</td>\n",
       "      <td>0.573309</td>\n",
       "      <td>0.710594</td>\n",
       "      <td>0.424316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>[0.84312148 0.61403509]</td>\n",
       "      <td>[0.87993283 0.53846154]</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.709197</td>\n",
       "      <td>0.437346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>[0.84441656 0.56578947]</td>\n",
       "      <td>[0.84760705 0.55976331]</td>\n",
       "      <td>0.562760</td>\n",
       "      <td>0.703685</td>\n",
       "      <td>0.408786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>[0.83484074 0.62134503]</td>\n",
       "      <td>[0.89126784 0.50295858]</td>\n",
       "      <td>0.555919</td>\n",
       "      <td>0.697113</td>\n",
       "      <td>0.424076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.7852</td>\n",
       "      <td>[0.82821609 0.61620795]</td>\n",
       "      <td>[0.89462636 0.47692308]</td>\n",
       "      <td>0.537692</td>\n",
       "      <td>0.685775</td>\n",
       "      <td>0.406356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fs-rf.s.ds_MA_tr.csv</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>[0.84902913 0.45758355]</td>\n",
       "      <td>[0.73425693 0.63195266]</td>\n",
       "      <td>0.530815</td>\n",
       "      <td>0.683105</td>\n",
       "      <td>0.335089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>[0.83305156 0.52264808]</td>\n",
       "      <td>[0.82745592 0.53254438]</td>\n",
       "      <td>0.527550</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.357844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s.ds_MA_tr.csv</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>[0.86587537 0.40142672]</td>\n",
       "      <td>[0.6125105  0.73254438]</td>\n",
       "      <td>0.518643</td>\n",
       "      <td>0.672527</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pca0.99.s.ds_MA_tr.csv</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>[0.80113867 0.46354167]</td>\n",
       "      <td>[0.8270361  0.42130178]</td>\n",
       "      <td>0.441414</td>\n",
       "      <td>0.624169</td>\n",
       "      <td>0.256379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MLA_dataset                    MLA Name  MLA Train Accuracy  \\\n",
       "1           s.ds_MA_tr.csv                   LinearSVC              0.8353   \n",
       "2           s.ds_MA_tr.csv          LogisticRegression              0.8356   \n",
       "3           s.ds_MA_tr.csv                         SVC              0.8394   \n",
       "1     fs-rf.s.ds_MA_tr.csv                   LinearSVC              0.8181   \n",
       "3     fs-rf.s.ds_MA_tr.csv                         SVC              0.8249   \n",
       "2     fs-rf.s.ds_MA_tr.csv          LogisticRegression              0.8215   \n",
       "1   pca0.99.s.ds_MA_tr.csv                   LinearSVC              0.8148   \n",
       "2   pca0.99.s.ds_MA_tr.csv          LogisticRegression              0.8126   \n",
       "9     fs-rf.s.ds_MA_tr.csv  GradientBoostingClassifier              0.8599   \n",
       "3   pca0.99.s.ds_MA_tr.csv                         SVC              0.8681   \n",
       "9           s.ds_MA_tr.csv  GradientBoostingClassifier              0.8721   \n",
       "4     fs-rf.s.ds_MA_tr.csv          AdaBoostClassifier              0.8373   \n",
       "4           s.ds_MA_tr.csv          AdaBoostClassifier              0.8429   \n",
       "6     fs-rf.s.ds_MA_tr.csv               MLPClassifier              0.8629   \n",
       "8     fs-rf.s.ds_MA_tr.csv      RandomForestClassifier              0.9664   \n",
       "6           s.ds_MA_tr.csv               MLPClassifier              0.9067   \n",
       "8           s.ds_MA_tr.csv      RandomForestClassifier              0.9664   \n",
       "6   pca0.99.s.ds_MA_tr.csv               MLPClassifier              0.9098   \n",
       "9   pca0.99.s.ds_MA_tr.csv  GradientBoostingClassifier              0.8541   \n",
       "10    fs-rf.s.ds_MA_tr.csv           BaggingClassifier              0.9591   \n",
       "10          s.ds_MA_tr.csv           BaggingClassifier              0.9590   \n",
       "11          s.ds_MA_tr.csv               XGBClassifier              0.9663   \n",
       "4   pca0.99.s.ds_MA_tr.csv          AdaBoostClassifier              0.8150   \n",
       "11    fs-rf.s.ds_MA_tr.csv               XGBClassifier              0.9617   \n",
       "0           s.ds_MA_tr.csv        KNeighborsClassifier              0.8571   \n",
       "0   pca0.99.s.ds_MA_tr.csv        KNeighborsClassifier              0.8562   \n",
       "0     fs-rf.s.ds_MA_tr.csv        KNeighborsClassifier              0.8540   \n",
       "7     fs-rf.s.ds_MA_tr.csv      DecisionTreeClassifier              0.9664   \n",
       "10  pca0.99.s.ds_MA_tr.csv           BaggingClassifier              0.9545   \n",
       "7           s.ds_MA_tr.csv      DecisionTreeClassifier              0.9664   \n",
       "11  pca0.99.s.ds_MA_tr.csv               XGBClassifier              0.9664   \n",
       "8   pca0.99.s.ds_MA_tr.csv      RandomForestClassifier              0.9663   \n",
       "5     fs-rf.s.ds_MA_tr.csv                  GaussianNB              0.7032   \n",
       "7   pca0.99.s.ds_MA_tr.csv      DecisionTreeClassifier              0.9664   \n",
       "5           s.ds_MA_tr.csv                  GaussianNB              0.6365   \n",
       "5   pca0.99.s.ds_MA_tr.csv                  GaussianNB              0.7197   \n",
       "\n",
       "    MLA Test Accuracy      MLA Test Precission          MLA Test Recall  \\\n",
       "1              0.8324  [0.96797153 0.62063492]  [0.7993283  0.92544379]   \n",
       "2              0.8333  [0.9661274  0.62289832]  [0.802267   0.92071006]   \n",
       "3              0.8289  [0.95979899 0.61843169]  [0.80184719 0.90532544]   \n",
       "1              0.8234  [0.95345345 0.61187958]  [0.79974811 0.88994083]   \n",
       "3              0.8224  [0.94622595 0.61333333]  [0.80520571 0.87100592]   \n",
       "2              0.8240  [0.9420078  0.61787234]  [0.81150294 0.8591716 ]   \n",
       "1              0.8187  [0.93765222 0.61073254]  [0.80814442 0.84852071]   \n",
       "2              0.8147  [0.93897638 0.60334728]  [0.80100756 0.85325444]   \n",
       "9              0.8401  [0.91319752 0.66976264]  [0.86565911 0.76804734]   \n",
       "3              0.8125  [0.92860589 0.60398614]  [0.80814442 0.82485207]   \n",
       "9              0.8351  [0.90605795 0.66491043]  [0.86649874 0.74674556]   \n",
       "4              0.8327  [0.90008688 0.66486486]  [0.86985726 0.72781065]   \n",
       "4              0.8262  [0.89951733 0.64978903]  [0.86062133 0.72899408]   \n",
       "6              0.8144  [0.87568479 0.6440281 ]  [0.87237615 0.65088757]   \n",
       "8              0.8069  [0.87762988 0.62360802]  [0.85810243 0.66272189]   \n",
       "6              0.8076  [0.87484036 0.62756264]  [0.8627204  0.65207101]   \n",
       "8              0.8079  [0.87330508 0.62975779]  [0.86523929 0.64615385]   \n",
       "6              0.7989  [0.87429806 0.60745614]  [0.84970613 0.6556213 ]   \n",
       "9              0.8162  [0.86614818 0.66071429]  [0.88832914 0.61301775]   \n",
       "10             0.8076  [0.86520116 0.6372549 ]  [0.87573468 0.61538462]   \n",
       "10             0.7980  [0.85951787 0.61753959]      [0.868178 0.6     ]   \n",
       "11             0.8029  [0.85720131 0.63346105]  [0.87951301 0.58698225]   \n",
       "4              0.8063  [0.8501395  0.65320334]  [0.89546599 0.55502959]   \n",
       "11             0.8004  [0.84843625 0.63710778]  [0.88832914 0.55266272]   \n",
       "0              0.7973  [0.84754626 0.62887989]  [0.8845508  0.55147929]   \n",
       "0              0.7945  [0.84643289 0.62198391]  [0.88161209 0.54911243]   \n",
       "0              0.7930  [0.84640259 0.61752988]  [0.8790932  0.55029586]   \n",
       "7              0.7791  [0.84756352 0.57990315]  [0.8543241  0.56686391]   \n",
       "10             0.7905  [0.84312148 0.61403509]  [0.87993283 0.53846154]   \n",
       "7              0.7722  [0.84441656 0.56578947]  [0.84760705 0.55976331]   \n",
       "11             0.7896  [0.83484074 0.62134503]  [0.89126784 0.50295858]   \n",
       "8              0.7852  [0.82821609 0.61620795]  [0.89462636 0.47692308]   \n",
       "5              0.7075  [0.84902913 0.45758355]  [0.73425693 0.63195266]   \n",
       "7              0.7502  [0.83305156 0.52264808]  [0.82745592 0.53254438]   \n",
       "5              0.6439  [0.86587537 0.40142672]  [0.6125105  0.73254438]   \n",
       "5              0.7208  [0.80113867 0.46354167]  [0.8270361  0.42130178]   \n",
       "\n",
       "    MLA Test F1_score  MLA Test AUC  MLA Test Matthews Coefficient  \n",
       "1            0.742993      0.862386                       0.653150  \n",
       "2            0.743075      0.861489                       0.652573  \n",
       "3            0.734870      0.853586                       0.639460  \n",
       "1            0.725169      0.844844                       0.624423  \n",
       "3            0.719804      0.838106                       0.615126  \n",
       "2            0.718812      0.835337                       0.612778  \n",
       "1            0.710253      0.828333                       0.600088  \n",
       "2            0.706863      0.827131                       0.595669  \n",
       "9            0.715546      0.816853                       0.607804  \n",
       "3            0.697349      0.816498                       0.580628  \n",
       "9            0.703456      0.806622                       0.591729  \n",
       "4            0.694915      0.798834                       0.581080  \n",
       "4            0.687117      0.794808                       0.569104  \n",
       "6            0.647440      0.761632                       0.521485  \n",
       "8            0.642570      0.760412                       0.510937  \n",
       "6            0.639582      0.757396                       0.508559  \n",
       "8            0.637850      0.755697                       0.507211  \n",
       "6            0.630620      0.752664                       0.493400  \n",
       "9            0.635973      0.750673                       0.513946  \n",
       "10           0.626129      0.745560                       0.496755  \n",
       "10           0.608643      0.734089                       0.472597  \n",
       "11           0.609337      0.733248                       0.478426  \n",
       "4            0.600128      0.725248                       0.476187  \n",
       "11           0.591888      0.720496                       0.462732  \n",
       "0            0.587642      0.718015                       0.455781  \n",
       "0            0.583281      0.715362                       0.449175  \n",
       "0            0.581977      0.714695                       0.446327  \n",
       "7            0.573309      0.710594                       0.424316  \n",
       "10           0.573770      0.709197                       0.437346  \n",
       "7            0.562760      0.703685                       0.408786  \n",
       "11           0.555919      0.697113                       0.424076  \n",
       "8            0.537692      0.685775                       0.406356  \n",
       "5            0.530815      0.683105                       0.335089  \n",
       "7            0.527550      0.680000                       0.357844  \n",
       "5            0.518643      0.672527                       0.303700  \n",
       "5            0.441414      0.624169                       0.256379  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = baseline_generator(listFiles_tr, listFiles_ts, outVar, WorkingFolder)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the previous result it seems that the minitrain.csv dataset tend to get better performances that s.ds_MA.tr.csv. On the other hand Gradient Boosting Classifier is the method that achieves better performance, so is probably a good candidate for the minitrain.csv dataset. We could try some combination of parameters on that dataset and algorithm in the gridsearch strategy. But before we go any further we can plot the ROC curves for this baseline so that we can have a graphic comparaison across the methods used for the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another notebook we will analyze how to look for a good combination of parameters for a set of chosen algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
